{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup:\n"
      ],
      "metadata": {
        "id": "hpx1JAesULnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Casey Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/ECE 661/Final Project')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKFRRB8qT9ED",
        "outputId": "90e56b19-efc8-41e3-b891-57ebf0975e64"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependencies\n",
        "import argparse\n",
        "import os, sys\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#from tools.dataset import CIFAR10\n",
        "#from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "MZVUD6-wUrnF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet Code"
      ],
      "metadata": {
        "id": "JHe82gKxiSnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Properly implemented ResNet-s for CIFAR10 as described in paper [1].\n",
        "The implementation and structure of this file is hugely influenced by [2]\n",
        "which is implemented for ImageNet and doesn't have option A for identity.\n",
        "Moreover, most of the implementations on the web is copy-paste from\n",
        "torchvision's resnet and has wrong number of params.\n",
        "Proper ResNet-s for CIFAR10 (for fair comparision and etc.) has following\n",
        "number of layers and parameters:\n",
        "name      | layers | params\n",
        "ResNet20  |    20  | 0.27M\n",
        "ResNet32  |    32  | 0.46M\n",
        "ResNet44  |    44  | 0.66M\n",
        "ResNet56  |    56  | 0.85M\n",
        "ResNet110 |   110  |  1.7M\n",
        "ResNet1202|  1202  | 19.4m\n",
        "which this implementation indeed has.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "[2] https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
        "If you use this implementation in you work, please don't forget to mention the\n",
        "author, Yerlan Idelbayev.\n",
        "'''\n",
        "\n",
        "__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n",
        "\n",
        "def _weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    #print(classname)\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight)\n",
        "\n",
        "class LambdaLayer(nn.Module):\n",
        "    def __init__(self, lambd):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, option='A'):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            if option == 'A':\n",
        "                \"\"\"\n",
        "                For CIFAR10 ResNet paper uses option A.\n",
        "                \"\"\"\n",
        "                self.shortcut = LambdaLayer(lambda x:\n",
        "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
        "            elif option == 'B':\n",
        "                self.shortcut = nn.Sequential(\n",
        "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                     nn.BatchNorm2d(self.expansion * planes)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "        self.apply(_weights_init)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, out.size()[3])\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def resnet20():\n",
        "    return ResNet(BasicBlock, [3, 3, 3])\n",
        "\n",
        "\n",
        "def resnet32():\n",
        "    return ResNet(BasicBlock, [5, 5, 5])\n",
        "\n",
        "\n",
        "def resnet44():\n",
        "    return ResNet(BasicBlock, [7, 7, 7])\n",
        "\n",
        "\n",
        "def resnet56():\n",
        "    return ResNet(BasicBlock, [9, 9, 9])\n",
        "\n",
        "\n",
        "def resnet110():\n",
        "    return ResNet(BasicBlock, [18, 18, 18])\n",
        "\n",
        "\n",
        "def resnet1202():\n",
        "    return ResNet(BasicBlock, [200, 200, 200])\n",
        "\n",
        "\n",
        "def test(net):\n",
        "    import numpy as np\n",
        "    total_params = 0\n",
        "\n",
        "    for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
        "        total_params += np.prod(x.data.numpy().shape)\n",
        "    print(\"Total number of params\", total_params)\n",
        "    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    for net_name in __all__:\n",
        "        if net_name.startswith('resnet'):\n",
        "            print(net_name)\n",
        "            test(globals()[net_name]())\n",
        "            print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rf2LOd_iRYV",
        "outputId": "86543cee-4c7d-4bfa-e1b2-9e8cf8410838"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resnet20\n",
            "Total number of params 269722\n",
            "Total layers 20\n",
            "\n",
            "resnet32\n",
            "Total number of params 464154\n",
            "Total layers 32\n",
            "\n",
            "resnet44\n",
            "Total number of params 658586\n",
            "Total layers 44\n",
            "\n",
            "resnet56\n",
            "Total number of params 853018\n",
            "Total layers 56\n",
            "\n",
            "resnet110\n",
            "Total number of params 1727962\n",
            "Total layers 110\n",
            "\n",
            "resnet1202\n",
            "Total number of params 19421274\n",
            "Total layers 1202\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RotNet"
      ],
      "metadata": {
        "id": "O7MPUvV5aLVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading in CIFAR Dataset\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=16)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ospo5D1LUnAi",
        "outputId": "386840f1-907d-4244-9933-e60ffda8aaf9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataloader\n",
        "# Each time an image is retrieved, return 4 images rotated by 0, 90, 180, and 270 degrees, with labels indicading which rotation is used\n",
        "\n",
        "class RotNetDataloader(DataLoader):\n",
        "  def __init__(self, dataset, batch_size):\n",
        "    self.dataset = dataset\n",
        "    self.batch_size = batch_size\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "yolGxdedtAIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RotNet Setup\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "net = ResNet(BasicBlock, [3, 3, 3], num_classes = 4)\n",
        "net.to(device)\n",
        "\n",
        "# Parameters (as described in the paper)\n",
        "INITIAL_LR = 0.1\n",
        "MOMENTUM = 0.9\n",
        "REG = 5e-4\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr = INITIAL_LR, momentum = MOMENTUM, weight_decay = REG)\n",
        "EPOCHS = 100\n",
        "DECAY_EPOCHS = {30, 60, 80}\n",
        "DECAY = 0.2"
      ],
      "metadata": {
        "id": "7ICT9X0XVsMT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rotnet Training\n",
        "CHECKPOINT_FOLDER = \"./content/drive/MyDrive/ECE 661/Final Project\"\n",
        "\n",
        "\n",
        "best_val_acc = 0\n",
        "current_learning_rate = INITIAL_LR\n",
        "\n",
        "print(\"==> Training starts!\")\n",
        "print(\"=\"*50)\n",
        "for i in range(0, EPOCHS):\n",
        "    # handle the learning rate scheduler.\n",
        "    if i in DECAY_EPOCHS:\n",
        "        current_learning_rate = current_learning_rate * DECAY\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = current_learning_rate\n",
        "        print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
        "    \n",
        "    # Training\n",
        "    net.train()\n",
        "    total_examples = 0\n",
        "    correct_examples = 0\n",
        "    train_loss = 0\n",
        "    \n",
        "    print(\"Epoch %d:\" %i)\n",
        "    \n",
        "    \n",
        "    # One Epoch\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        out = net.forward(inputs)\n",
        "        loss = criterion(out, targets)\n",
        "        net.zero_grad()\n",
        "        loss.backward()\n",
        "        train_loss += loss\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Counting Correct Predictions\n",
        "        for idx, val in enumerate(out):\n",
        "          max_out_idx = torch.argmax(val)\n",
        "          target_idx = targets[idx]\n",
        "\n",
        "          if max_out_idx == target_idx:\n",
        "            correct_examples += 1\n",
        "          \n",
        "          total_examples += 1\n",
        "\n",
        "\n",
        "    # Compute Loss/Accuracy     \n",
        "    avg_loss = train_loss / len(train_loader)\n",
        "    avg_acc = correct_examples / total_examples\n",
        "    print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
        "\n",
        "    # Validation\n",
        "    net.eval()\n",
        "    total_examples = 0\n",
        "    correct_examples = 0\n",
        "    val_loss = 0\n",
        "\n",
        "    # disable gradient during validation, which can save GPU memory\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            out = net.forward(inputs)\n",
        "            loss = criterion(out, targets)\n",
        "            val_loss += loss\n",
        "\n",
        "            # Counting Correct Predictions\n",
        "            for idx, val in enumerate(out):\n",
        "              max_out_idx = torch.argmax(val)\n",
        "              target_idx = targets[idx]\n",
        "\n",
        "              if max_out_idx == target_idx:\n",
        "                correct_examples += 1\n",
        "              \n",
        "              total_examples += 1\n",
        "\n",
        "    avg_loss = val_loss / len(val_loader)\n",
        "    avg_acc = correct_examples / total_examples\n",
        "    print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
        "    \n",
        "    # save the model checkpoint\n",
        "    if avg_acc > best_val_acc:\n",
        "        best_val_acc = avg_acc\n",
        "        if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "            os.makedirs(CHECKPOINT_FOLDER)\n",
        "        print(\"Saving ...\")\n",
        "        state = {'state_dict': net.state_dict(),\n",
        "                 'epoch': i,\n",
        "                 'lr': current_learning_rate}\n",
        "        torch.save(state, os.path.join(CHECKPOINT_FOLDER, 'RotNet.pth'))\n",
        "        \n",
        "    print('')\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "6i16vO98WeAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}