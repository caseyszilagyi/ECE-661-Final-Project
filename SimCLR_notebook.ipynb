{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb0660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from train import SimCLR_Train\n",
    "from models import SimCLR_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# install required packages\n",
    "!pip install pytorch-ignite\n",
    "!pip install torchlars"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# credit: https://github.com/kuangliu/pytorch-cifar/issues/19\n",
    "# for CIFAR-10 normalization values\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "batch_size_list = [256, 512, 1024, 2048, 4096]\n",
    "\n",
    "# the maximum batchsize is 1024\n",
    "batch_size = batch_size_list[3]\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                        download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet20 = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=False)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = SimCLR_Model(base_encoder=resnet20)\n",
    "net = net.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# uncomment this line if using adam\n",
    "# train_loss_list = SimCLR_Train(net, device, batch_size, train_loader, num_epoch=100, temp=0.5, lr=1e-4, optim='adam', lr_scheduler='None')\n",
    "\n",
    "# this line for lars\n",
    "# temp = [0.1, 0.5, 1.0]\n",
    "# lr = [0.5, 1.0, 1.5]\n",
    "# epoch = [100, 200, 300]\n",
    "train_loss_list = SimCLR_Train(net, device, batch_size, train_loader, num_epoch=100, temp=0.5, lr=1, optim='lars', lr_scheduler='cosine')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9635fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this line if using adam\n",
    "# train_loss_list = SimCLR_Train(net, device, batch_size, train_loader, num_epoch=100, temp=0.5, lr=1e-4, optim='adam', lr_scheduler='None')\n",
    "\n",
    "# this line for lars\n",
    "# temp = [0.1, 0.5, 1.0]\n",
    "# lr = [0.5, 1.0, 1.5]\n",
    "# epoch = [100, 200, 300]\n",
    "train_loss_list = SimCLR_Train(net, device, batch_size, train_loader, num_epoch=100, temp=0.5, lr=1, optim='lars', lr_scheduler='cosine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}